networks:
  app-tier:
    driver: bridge
services:
  cercat-blue:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - app-tier
    image: ghcr.io/jiwonkkang/cercat:latest
    depends_on:
      - redis
      - kafka
    environment:
      - BUCKET_NAME=${BUCKET_NAME}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - SPRING_PROFILES_ACTIVE=${SPRING_PROFILES_ACTIVE}
      - SPRING_DATABASE_HOST=${SPRING_DATABASE_HOST}
      - SPRING_DATABASE_PORT=${SPRING_DATABASE_PORT}
      - SPRING_DATABASE_USERNAME=${SPRING_DATABASE_USERNAME}
      - SPRING_DATABASE_PASSWORD=${SPRING_DATABASE_PASSWORD}
      - GCS_KEY=${GCS_KEY}
      - KAKAO_API_KEY=${KAKAO_API_KEY}
      - KAKAO_REDIRECT_URI=${KAKAO_REDIRECT_URI}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - SECRET_KEY=${SECRET_KEY}
    restart: always
    healthcheck:
      test: "curl -f http://localhost:8080/health || exit 1"
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 30s
  cercat-green:
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - app-tier
    image: ghcr.io/jiwonkkang/cercat:latest
    depends_on:
      - redis
      - kafka
    environment:
      - BUCKET_NAME=${BUCKET_NAME}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - SPRING_PROFILES_ACTIVE=${SPRING_PROFILES_ACTIVE}
      - SPRING_DATABASE_HOST=${SPRING_DATABASE_HOST}
      - SPRING_DATABASE_PORT=${SPRING_DATABASE_PORT}
      - SPRING_DATABASE_USERNAME=${SPRING_DATABASE_USERNAME}
      - SPRING_DATABASE_PASSWORD=${SPRING_DATABASE_PASSWORD}
      - GCS_KEY=${GCS_KEY}
      - KAKAO_API_KEY=${KAKAO_API_KEY}
      - KAKAO_REDIRECT_URI=${KAKAO_REDIRECT_URI}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - SECRET_KEY=${SECRET_KEY}
    restart: always
    healthcheck:
      test: "curl -f http://localhost:8080/health || exit 1"
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 30s
  cercat-batch:
    container_name: cercat-batch
    extra_hosts:
      - "host.docker.internal:host-gateway"
    image: ghcr.io/jiwonkkang/cercat-batch:latest
    environment:
      - BUCKET_NAME=${BUCKET_NAME}
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - SPRING_PROFILES_ACTIVE=${SPRING_PROFILES_ACTIVE}
      - SPRING_DATABASE_HOST=${SPRING_DATABASE_HOST}
      - SPRING_DATABASE_PORT=${SPRING_DATABASE_PORT}
      - SPRING_DATABASE_USERNAME=${SPRING_DATABASE_USERNAME}
      - SPRING_DATABASE_PASSWORD=${SPRING_DATABASE_PASSWORD}
      - GCS_KEY=${GCS_KEY}
      - KAKAO_API_KEY=${KAKAO_API_KEY}
      - KAKAO_REDIRECT_URI=${KAKAO_REDIRECT_URI}
      - CLIENT_SECRET=${CLIENT_SECRET}
      - SECRET_KEY=${SECRET_KEY}
    networks:
      - app-tier
    ports:
      - "8082:8081"
  redis:
    container_name: cercat-redis
    networks:
      - app-tier
    image: redis:latest
    ports:
      - "6379:6379"
  zookeeper:
    container_name: cercat-zookeeper
    image: confluentinc/cp-zookeeper:latest
    networks:
      - app-tier
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "22181:2181"
  kafka:
    container_name: cercat-kafka
    image: confluentinc/cp-kafka:latest
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - app-tier
    depends_on:
      - zookeeper
    ports:
      - "29092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8989:8080"
    networks:
      - app-tier
    restart: always
    depends_on:
      - kafka
      - zookeeper
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
  kafka-connect:
    build:
      context: ../docker-compose/connect
      dockerfile: ../docker-compose/connect/Dockerfile
    links:
      - zookeeper
      - kafka
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - kafka
    ports:
      - '8083:8083'
    networks:
      - app-tier
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: /usr/share/java
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      CONNECT_REST_HOST_NAME: 0.0.0.0
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083\
  es:
    build:
      context: ../docker-compose/elastic-search
      dockerfile: ../docker-compose/elastic-search/Dockerfile
    environment:
      - node.name=es-node
      - cluster.name=search-cluster
      - discovery.type=single-node
      - ingest.geoip.downloader.enabled=false
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    mem_limit: 2147483648
    volumes:
      - ./elastic-search/data:/usr/share/elasticsearch/data
    networks:
      - app-tier
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - '9200:9200'
      - '9300:9300'

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:8.5.3
    networks:
      - app-tier
    environment:
      SERVER_NAME: kibana
      ELASTICSEARCH_HOSTS: http://es:9200
    ports:
      - 5601:5601
    depends_on:
      - es
  nginx:
    image: nginx:1.15-alpine
    container_name: nginx
    networks:
      - app-tier
    restart: unless-stopped
    volumes:
      - ./data/nginx/nginx.conf:/etc/nginx/conf.d/nginx.conf
      - ./nginx/log:/var/log/nginx
      - /etc/localtime:/etc/localtime
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    ports:
      - "80:80"
      - "443:443"
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"
  logstash:
    build:
      context: logstash
      args:
        ELASTIC_VERSION: 8.5.3
    volumes:
      - /etc/localtime:/etc/localtime
      - ./logstash/logstash.json:/usr/share/logstash/logstash.json
      - ./nginx/log:/var/log/nginx
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
    environment:
      TZ: "Asia/Seoul"
      LS_JAVA_OPTS: -Xms256m -Xmx256m
    networks:
      - app-tier
    depends_on:
      - es
    restart: unless-stopped